{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3d34e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import env\n",
    "import wrangle_cluster\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba61873",
   "metadata": {},
   "source": [
    "## Acquire (acquire.py)\n",
    "\n",
    "Zillow\n",
    "\n",
    "For the following, iterate through the steps you would take to create functions: Write the code to do the following in a jupyter notebook, test it, convert to functions, then create the file to house those functions.\n",
    "\n",
    "You will have a zillow.ipynb file and a helper file for each section in the pipeline.\n",
    "\n",
    "acquire & summarize\n",
    "\n",
    "1. Acquire data from mySQL using the python module to connect and query. You will want to end with a single dataframe. Make sure to include: the logerror, all fields related to the properties that are available. You will end up using all the tables in the database.\n",
    "\n",
    "- Be sure to do the correct join (inner, outer, etc.). We do not want to eliminate properties purely because they may have a null value for airconditioningtypeid.\n",
    "- Only include properties with a transaction in 2017, and include only the last transaction for each property (so no duplicate property ID's), along with zestimate error and date of transaction.\n",
    "- Only include properties that include a latitude and longitude value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ff45f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7275ea081d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sql' is not defined"
     ]
    }
   ],
   "source": [
    "df = wrangle_cluster.get_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e3cb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>fips</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>rawcensustractandblock</th>\n",
       "      <th>regionidcity</th>\n",
       "      <th>...</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>heatingorsystemdesc</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>33634931.0</td>\n",
       "      <td>-117869207.0</td>\n",
       "      <td>4506.0</td>\n",
       "      <td>6.059063e+07</td>\n",
       "      <td>53571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>485713.0</td>\n",
       "      <td>1023282.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>537569.0</td>\n",
       "      <td>11013.72</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>34449266.0</td>\n",
       "      <td>-119281531.0</td>\n",
       "      <td>12647.0</td>\n",
       "      <td>6.111001e+07</td>\n",
       "      <td>13091.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>464000.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>376000.0</td>\n",
       "      <td>5672.48</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>Ventura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>33886168.0</td>\n",
       "      <td>-117823170.0</td>\n",
       "      <td>8432.0</td>\n",
       "      <td>6.059022e+07</td>\n",
       "      <td>21412.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>85289.0</td>\n",
       "      <td>564778.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>479489.0</td>\n",
       "      <td>6488.30</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>34245180.0</td>\n",
       "      <td>-118240722.0</td>\n",
       "      <td>13038.0</td>\n",
       "      <td>6.037300e+07</td>\n",
       "      <td>396551.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>108918.0</td>\n",
       "      <td>145143.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>36225.0</td>\n",
       "      <td>1777.51</td>\n",
       "      <td>-0.103410</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Central</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>34185120.0</td>\n",
       "      <td>-118414640.0</td>\n",
       "      <td>278581.0</td>\n",
       "      <td>6.037124e+07</td>\n",
       "      <td>12447.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>73681.0</td>\n",
       "      <td>119407.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>45726.0</td>\n",
       "      <td>1533.89</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Central</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathroomcnt  bedroomcnt  buildingqualitytypeid  \\\n",
       "0          3.5         4.0                    6.0   \n",
       "1          1.0         2.0                    6.0   \n",
       "2          2.0         3.0                    6.0   \n",
       "3          3.0         4.0                    8.0   \n",
       "4          3.0         3.0                    8.0   \n",
       "\n",
       "   calculatedfinishedsquarefeet    fips    latitude    longitude  \\\n",
       "0                        3100.0  6059.0  33634931.0 -117869207.0   \n",
       "1                        1465.0  6111.0  34449266.0 -119281531.0   \n",
       "2                        1243.0  6059.0  33886168.0 -117823170.0   \n",
       "3                        2376.0  6037.0  34245180.0 -118240722.0   \n",
       "4                        1312.0  6037.0  34185120.0 -118414640.0   \n",
       "\n",
       "   lotsizesquarefeet  rawcensustractandblock  regionidcity  ...  yearbuilt  \\\n",
       "0             4506.0            6.059063e+07       53571.0  ...     1998.0   \n",
       "1            12647.0            6.111001e+07       13091.0  ...     1967.0   \n",
       "2             8432.0            6.059022e+07       21412.0  ...     1962.0   \n",
       "3            13038.0            6.037300e+07      396551.0  ...     1970.0   \n",
       "4           278581.0            6.037124e+07       12447.0  ...     1964.0   \n",
       "\n",
       "   structuretaxvaluedollarcnt  taxvaluedollarcnt  assessmentyear  \\\n",
       "0                    485713.0          1023282.0          2016.0   \n",
       "1                     88000.0           464000.0          2016.0   \n",
       "2                     85289.0           564778.0          2016.0   \n",
       "3                    108918.0           145143.0          2016.0   \n",
       "4                     73681.0           119407.0          2016.0   \n",
       "\n",
       "   landtaxvaluedollarcnt  taxamount  logerror  transactiondate  \\\n",
       "0               537569.0   11013.72  0.025595       2017-01-01   \n",
       "1               376000.0    5672.48  0.055619       2017-01-01   \n",
       "2               479489.0    6488.30  0.005383       2017-01-01   \n",
       "3                36225.0    1777.51 -0.103410       2017-01-01   \n",
       "4                45726.0    1533.89  0.006940       2017-01-01   \n",
       "\n",
       "   heatingorsystemdesc       county  \n",
       "0                 None       Orange  \n",
       "1                 None      Ventura  \n",
       "2                 None       Orange  \n",
       "3              Central  Los Angeles  \n",
       "4              Central  Los Angeles  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33b20c",
   "metadata": {},
   "source": [
    "## 2. Summarize your data (summary stats, info, dtypes, shape, distributions, value_counts, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ceb1ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69523 entries, 0 to 77380\n",
      "Data columns (total 24 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   bathroomcnt                   69523 non-null  float64\n",
      " 1   bedroomcnt                    69523 non-null  float64\n",
      " 2   buildingqualitytypeid         69523 non-null  float64\n",
      " 3   calculatedfinishedsquarefeet  69523 non-null  float64\n",
      " 4   fips                          69523 non-null  float64\n",
      " 5   latitude                      69523 non-null  float64\n",
      " 6   longitude                     69523 non-null  float64\n",
      " 7   lotsizesquarefeet             69523 non-null  float64\n",
      " 8   rawcensustractandblock        69523 non-null  float64\n",
      " 9   regionidcity                  69523 non-null  float64\n",
      " 10  regionidcounty                69523 non-null  float64\n",
      " 11  regionidzip                   69523 non-null  float64\n",
      " 12  roomcnt                       69523 non-null  float64\n",
      " 13  unitcnt                       69523 non-null  float64\n",
      " 14  yearbuilt                     69523 non-null  float64\n",
      " 15  structuretaxvaluedollarcnt    69523 non-null  float64\n",
      " 16  taxvaluedollarcnt             69523 non-null  float64\n",
      " 17  assessmentyear                69523 non-null  float64\n",
      " 18  landtaxvaluedollarcnt         69523 non-null  float64\n",
      " 19  taxamount                     69523 non-null  float64\n",
      " 20  logerror                      69523 non-null  float64\n",
      " 21  transactiondate               69523 non-null  object \n",
      " 22  heatingorsystemdesc           69523 non-null  object \n",
      " 23  county                        69523 non-null  object \n",
      "dtypes: float64(21), object(3)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3dc39",
   "metadata": {},
   "source": [
    "## 3. Write a function that takes in a dataframe of observations and attributes and returns a dataframe where each row is an atttribute name, the first column is the number of rows with missing values for that attribute, and the second column is percent of total rows that have missing values for that attribute. Run the function and document takeaways from this on how you want to handle missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae165084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_col(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    rows = df.shape[0]\n",
    "    prcnt_miss = num_missing / rows * 100\n",
    "    cols_missing = pd.DataFrame({'num_rows_missing': num_missing, 'percent_rows_missing': prcnt_miss})\n",
    "    return cols_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736a3ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_rows_missing</th>\n",
       "      <th>percent_rows_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bathroomcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroomcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rawcensustractandblock</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionidcity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionidcounty</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionidzip</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roomcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearbuilt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assessmentyear</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxamount</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logerror</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactiondate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heatingorsystemdesc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              num_rows_missing  percent_rows_missing\n",
       "bathroomcnt                                  0                   0.0\n",
       "bedroomcnt                                   0                   0.0\n",
       "buildingqualitytypeid                        0                   0.0\n",
       "calculatedfinishedsquarefeet                 0                   0.0\n",
       "fips                                         0                   0.0\n",
       "latitude                                     0                   0.0\n",
       "longitude                                    0                   0.0\n",
       "lotsizesquarefeet                            0                   0.0\n",
       "rawcensustractandblock                       0                   0.0\n",
       "regionidcity                                 0                   0.0\n",
       "regionidcounty                               0                   0.0\n",
       "regionidzip                                  0                   0.0\n",
       "roomcnt                                      0                   0.0\n",
       "unitcnt                                      0                   0.0\n",
       "yearbuilt                                    0                   0.0\n",
       "structuretaxvaluedollarcnt                   0                   0.0\n",
       "taxvaluedollarcnt                            0                   0.0\n",
       "assessmentyear                               0                   0.0\n",
       "landtaxvaluedollarcnt                        0                   0.0\n",
       "taxamount                                    0                   0.0\n",
       "logerror                                     0                   0.0\n",
       "transactiondate                              0                   0.0\n",
       "heatingorsystemdesc                          0                   0.0\n",
       "county                                       0                   0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls_by_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453b56e",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "- varied number of null values\n",
    "- drop columns that have more than 50% missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea6fd9",
   "metadata": {},
   "source": [
    "## 3.1. Write a function that takes in a dataframe and returns a dataframe with 3 columns: the number of columns missing, percent of columns missing, and number of rows with n columns missing. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_by_row(df):\n",
    "    num_missing = df.isnull().sum(axis=1)\n",
    "    prcnt_miss = num_missing / df.shape[1] * 100\n",
    "    rows_missing = pd.DataFrame({'num_cols_missing': num_missing, 'percent_cols_missing': prcnt_miss})\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['num_cols_missing', 'percent_cols_missing']).count()\\\n",
    "    .rename(index=str, columns={'index': 'num_rows'}).reset_index().set_index('num_cols_missing')\n",
    "    return rows_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1536fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_by_row(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857fa85d",
   "metadata": {},
   "source": [
    "#### Takeaways:\n",
    "- 5775 rows that are missing 36 columns\n",
    "- drop rows that have more than 75% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize data in the df\n",
    "#head, info, describe, value counts, nulls\n",
    "\n",
    "def summarize(df):\n",
    "    '''\n",
    "    this function will take in a single argument (a pandas df) \n",
    "    output to console various statistics on said dataframe, including:\n",
    "    #.head()\n",
    "    #.info()\n",
    "    #.describe()\n",
    "    #.value_counts()\n",
    "    #observation of nulls in the dataframe\n",
    "    '''\n",
    "    #print head\n",
    "    print('=================================================')\n",
    "    print('Dataframe head: ')\n",
    "    print(df.head(3))\n",
    "    \n",
    "    #print info\n",
    "    print('=================================================')\n",
    "    print('Dataframe info: ')\n",
    "    print(df.info())\n",
    "    \n",
    "    #print descriptive stats\n",
    "    print('=================================================')\n",
    "    print('Dataframe Description: ')\n",
    "    print(df.describe())\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != 'O'] # not an object\n",
    "    cat_cols = [col for col in df.columns if col not in num_cols]\n",
    "    \n",
    "    #print value counts\n",
    "    print('=================================================')\n",
    "    print('Dataframe value counts: ')\n",
    "    for col in df. columns:\n",
    "        if col in cat_cols:\n",
    "            print(df[col].value_counts())\n",
    "        else:\n",
    "            print(df[col].value_counts(bins=10, sort = False))\n",
    "    \n",
    "    #print nulls by column\n",
    "    print('=================================================')\n",
    "    print('nulls in dataframe by column: ')\n",
    "    print(nulls_by_col(df))\n",
    "    \n",
    "    #print nulls by row\n",
    "    \n",
    "    print('=================================================')\n",
    "    print('nulls in dataframe by row: ')\n",
    "    print(nulls_by_row(df))\n",
    "    print('=================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ccf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e58080",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "\n",
    "## 1. Remove any properties that are likely to be something other than single unit properties. (e.g. no duplexes, no land/lot, ...). There are multiple ways to estimate that a property is a single unit, and there is not a single \"right\" answer. But for this exercise, do not purely filter by unitcnt as we did previously. Add some new logic that will reduce the number of properties that are falsely removed. You might want to use # bedrooms, square feet, unit type or the like to then identify those with unitcnt not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b41b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict df to only properties that meet single use criteria\n",
    "single_use = [261, 262, 263, 264, 266, 268, 273, 276, 279]\n",
    "df = df[df.propertylandusetypeid.isin(single_use)]\n",
    "\n",
    "# Restrict df to only those properties with at least 1 bath & bed and 350 sqft area\n",
    "df = df[(df.bedroomcnt > 0) & (df.bathroomcnt > 0) & ((df.unitcnt<=1)|df.unitcnt.isnull())\\\n",
    "            & (df.calculatedfinishedsquarefeet>350)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize my numerical data types\n",
    "\n",
    "df.hist(figsize=(24,24), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e676813",
   "metadata": {},
   "source": [
    "## 2. Create a function that will drop rows or columns based on the percent of values that are missing: handle_missing_values(df, prop_required_column, prop_required_row).\n",
    "\n",
    "- The input:\n",
    "- A dataframe\n",
    "- A number between 0 and 1 that represents the proportion, for each column, of rows with non-missing values required to keep the column. i.e. if prop_required_column = .6, then you are requiring a column to have at least 60% of values not-NA (no more than 40% missing).\n",
    "- A number between 0 and 1 that represents the proportion, for each row, of columns/variables with non-missing values required to keep the row. For example, if prop_required_row = .75, then you are requiring a row to have at least 75% of variables with a non-missing value (no more that 25% missing).\n",
    "- The output:\n",
    "- The dataframe with the columns and rows dropped as indicated. Be sure to drop the columns prior to the rows in your function.\n",
    "- hint:\n",
    "- Look up the dropna documentation.\n",
    "- You will want to compute a threshold from your input values (prop_required) and total number of rows or columns.\n",
    "- Make use of inplace, i.e. inplace=True/False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_column = .5, prop_required_row = .75):\n",
    "# function that will drop rows or columns based on the percent of values that are missing:\\\n",
    "# handle_missing_values(df, prop_required_column, prop_required_row\n",
    "    threshold = int(round(prop_required_column*len(df.index),0))\n",
    "    df = df.dropna(axis=1, thresh=threshold)\n",
    "    threshold = int(round(prop_required_row*len(df.columns),0))\n",
    "    df.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values i.e. drop columns and rows based on a threshold\n",
    "df = handle_missing_values(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b16d98",
   "metadata": {},
   "source": [
    "## 3. Decide how to handle the remaining missing values:\n",
    "\n",
    "- Fill with constant value.\n",
    "- Impute with mean, median, mode.\n",
    "- Drop row/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18355970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for counties\n",
    "df['county'] = df['fips'].apply(\n",
    "        lambda x: 'Los Angeles' if x == 6037\\\n",
    "        else 'Orange' if x == 6059\\\n",
    "        else 'Ventura')\n",
    "\n",
    "# drop unnecessary columns\n",
    "dropcols = ['parcelid',\n",
    "         'calculatedbathnbr',\n",
    "         'finishedsquarefeet12',\n",
    "         'fullbathcnt',\n",
    "         'heatingorsystemtypeid',\n",
    "         'propertycountylandusecode',\n",
    "         'propertylandusetypeid',\n",
    "         'propertyzoningdesc',\n",
    "         'censustractandblock',\n",
    "         'propertylandusedesc']\n",
    "\n",
    "\n",
    "\n",
    "# replace nulls in unitcnt with 1\n",
    "df.unitcnt.fillna(1, inplace = True)\n",
    "\n",
    "# assume that since this is Southern CA, null means 'None' for heating system\n",
    "df.heatingorsystemdesc.fillna('None', inplace = True)\n",
    "\n",
    "# replace nulls with median values for select columns\n",
    "df.lotsizesquarefeet.fillna(7313, inplace = True)\n",
    "df.buildingqualitytypeid.fillna(6.0, inplace = True)\n",
    "\n",
    "# Columns to look for outliers\n",
    "df = df[df.taxvaluedollarcnt < 5_000_000]\n",
    "df = df[df.calculatedfinishedsquarefeet < 8000]\n",
    "\n",
    "# Just to be sure we caught all nulls, drop them here\n",
    "df = df.dropna()\n",
    "\n",
    "def remove_columns(df, cols_to_remove):\n",
    "#remove columns not needed\n",
    "    df = df.drop(columns=cols_to_remove)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_columns(df, dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aae194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202ec43",
   "metadata": {},
   "source": [
    "## Mall Customers\n",
    "### notebook\n",
    "#### 1. Acquire data from mall_customers.customers in mysql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from our acquire.py:\n",
    "def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "    \n",
    "def get_mallcustomer_data():\n",
    "    df = pd.read_sql('SELECT * FROM customers;', get_connection('mall_customers'))\n",
    "    return df.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d483eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall_df = get_mallcustomer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4c3a2",
   "metadata": {},
   "source": [
    "## 2. Summarize data (include distributions and descriptive statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03048101",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(mall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall_df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fbe413",
   "metadata": {},
   "source": [
    "## 3. Detect outliers using IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_function(df, cols, k):\n",
    "# function to detect and handle oulier using IQR rule\n",
    "    for col in df[cols]:\n",
    "        q1 = df.annual_income.quantile(0.25)\n",
    "        q3 = df.annual_income.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_bound =  q3 + k * iqr\n",
    "        lower_bound =  q1 - k * iqr\n",
    "        df = df[(df[col] < upper_bound) & (df[col] > lower_bound)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ee3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall_df = outlier_function(mall_df, ['age', 'spending_score', 'annual_income'], 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc578932",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(mall_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f72b4a",
   "metadata": {},
   "source": [
    "## 4. Split data (train, validate, and test split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06dadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df into test (20%) and train_validate (80%)\n",
    "train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "\n",
    "# split train_validate off into train (70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "train, validate = train_test_split(train_validate, test_size=.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55f872",
   "metadata": {},
   "source": [
    "## 5. Encode categorical columns using a one hot encoder (pd.get_dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b345da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(mall_df.gender, drop_first=True) # the only catagorical column\n",
    "mall_df = pd.concat([mall_df, dummy_df], axis=1).drop(columns=['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3743e80",
   "metadata": {},
   "source": [
    "## 6. Handles missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no missing values\n",
    "mall_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ab721",
   "metadata": {},
   "source": [
    "## 7. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(train, valid, test):\n",
    "    '''\n",
    "    Uses the train & test datasets created by the split_my_data function\n",
    "    Returns 3 items: mm_scaler, train_scaled_mm, test_scaled_mm\n",
    "    This is a linear transformation. Values will lie between 0 and 1\n",
    "    '''\n",
    "    num_vars = list(train.select_dtypes('number').columns) # taking in columns that are only numerical\n",
    "    scaler = MinMaxScaler()\n",
    "    train[num_vars] = scaler.fit_transform(train[num_vars])\n",
    "    valid[num_vars] = scaler.transform(valid[num_vars])\n",
    "    test[num_vars] = scaler.transform(test[num_vars])\n",
    "    return scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train, val, test = acquire.wrangle_mall_df()\n",
    "#min_max_scaler(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21261eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
